{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Production_Code_fine_tunning_QARiB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b7fcee4b2034b3db427fe124ecf901e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44d71c990df044d4a15d6d75d0c5d474",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f2e7c5d5a634f16ade73da1b519da79",
              "IPY_MODEL_4e05fb678b8548bcb00968112a3dba64"
            ]
          }
        },
        "44d71c990df044d4a15d6d75d0c5d474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f2e7c5d5a634f16ade73da1b519da79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aec0616913b24287a01e396430cbc284",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 543452854,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 543452854,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94bf31fee4b749ba9f73737c9a571c20"
          }
        },
        "4e05fb678b8548bcb00968112a3dba64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b801888285e4701a1e82ed7f08d4338",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 543M/543M [00:32&lt;00:00, 16.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_265a315748304e4ebd1b729cc48e80b3"
          }
        },
        "aec0616913b24287a01e396430cbc284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94bf31fee4b749ba9f73737c9a571c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b801888285e4701a1e82ed7f08d4338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "265a315748304e4ebd1b729cc48e80b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdD8MmEtMYUv",
        "outputId": "780cce0c-14c0-43b5-87ab-cafe72cb8712"
      },
      "source": [
        "!pip install optuna==2.3.0\n",
        "!pip install transformers==4.2.1\n",
        "!pip install farasapy\n",
        "!pip install pyarabic\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 26.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30kB 29.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 20.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 71kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 92kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 174kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 184kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 194kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 204kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 215kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 225kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 235kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 245kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 256kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 8.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (4.41.1)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.19.5)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (20.9)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.4.18)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.3.0) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.3.0) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.3.0) (2.4.7)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/6a/e929ec70ca05c5962f6541ef29fb9c207dd41f0f2333680fa39f44fa4357/cmd2-2.1.1-py3-none-any.whl (140kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 16.5MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 19.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.3.0) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna==2.3.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (3.7.4.3)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (21.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.3.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna==2.3.0) (3.4.1)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-cp37-none-any.whl size=359773 sha256=5825ac57d0010c00d5a1be4b59c094e11674639091b23361070138b92b905d1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=b37b2bb7b468ce38126f347fe90c8cda8fdbdbb51c6f766778ba3eba33f6ef49\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: colorlog, pbr, stevedore, pyperclip, colorama, cmd2, cliff, cmaes, Mako, python-editor, alembic, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.1 colorama-0.4.4 colorlog-5.0.1 optuna-2.3.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n",
            "Collecting transformers==4.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 8.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.1) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.1) (3.4.1)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.9.4 transformers-4.2.1\n",
            "Collecting farasapy\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/69/39ead86569e95141eede67703a93585be8454a801b7aab93ad1a7f0a8375/farasapy-0.0.13-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.24.3)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.13\n",
            "Collecting pyarabic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/e2/46728ec2f6fe14970de5c782346609f0636262c0941228f363710903aaa1/PyArabic-0.6.10.tar.gz (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyarabic\n",
            "  Building wheel for pyarabic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyarabic: filename=PyArabic-0.6.10-cp37-none-any.whl size=113324 sha256=6f33e6909103df4dfe05f5459db6688a08d1455e0f6344c4968aaa1026760f05\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/b8/f5/b7c1a50e6efb83544844f165a9b134afe7292585465e29b61d\n",
            "Successfully built pyarabic\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFtDemzeXK_8"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.utils import resample\n",
        "import logging\n",
        "import torch\n",
        "import optuna "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IYJ42tQ318w"
      },
      "source": [
        "# (1)load libraries \n",
        "import json, sys, regex\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "##----------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "##------------------------------------------------------\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM5aKhf4Mlfv"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        train,\n",
        "        test,\n",
        "        label_list,\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzA1zxZ7NE2l"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(BERTDataset).__init__()\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "\n",
        "\n",
        "        \n",
        "      input_ids = self.tokenizer.encode(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          truncation='longest_first'\n",
        "      )     \n",
        "    \n",
        "      attention_mask = [1] * len(input_ids)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      padding_length = self.max_len - len(input_ids)\n",
        "      input_ids = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
        "      attention_mask = attention_mask + ([0] * padding_length)    \n",
        "      \n",
        "      return InputFeatures(input_ids=input_ids, attention_mask=attention_mask, label=self.label_map[self.target[item]])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-gw9eXUPAav"
      },
      "source": [
        "class BERTDatasetTest(Dataset):\n",
        "    def __init__(self, text, model_name, max_len, label_map):\n",
        "      super(BERTDataset).__init__()\n",
        "      self.text = text\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "\n",
        "\n",
        "        \n",
        "      input_ids = self.tokenizer.encode(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          truncation='longest_first'\n",
        "      )     \n",
        "    \n",
        "      attention_mask = [1] * len(input_ids)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      padding_length = self.max_len - len(input_ids)\n",
        "      input_ids = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
        "      attention_mask = attention_mask + ([0] * padding_length)    \n",
        "      \n",
        "      return InputFeatures(input_ids=input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsddGpRf61WO"
      },
      "source": [
        "# MODEL_PATH_BEGIN_FINETUNE='/content/MARBERT_pytorch_verison'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqtS9ym3c_RL",
        "outputId": "f64ff5e1-4ea7-489e-c26b-90f07623f260"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"your device \", device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your device  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ewzCNgb3-dS"
      },
      "source": [
        "class SentimentIdentificationQarib(object):\n",
        "  \"\"\"A class for finetunning, evaluating and running the sentiment classification on Qarib model\n",
        "     After initializing an instance, you must\n",
        "    run the train method once before using it.\n",
        "    Args:\n",
        "        labels (:obj:`set` of :obj:`str`, optional): The set of sentiment labels\n",
        "            used in the training data in the main model.\n",
        "            If None, the default labels are used.\n",
        "            Defaults to None.\n",
        "\n",
        "        max_seq_length (:obj:`int`, optional): maximum sequence length for the model\n",
        "            \n",
        "            If None, the default max_seq_length are used.\n",
        "            Defaults to 256 .\n",
        "\n",
        "        num_epoch (:obj:`int`, optional): number of epoch used for training the model\n",
        "            \n",
        "            If None, the default num_epoch are used.\n",
        "            Defaults to 3 .\n",
        "\n",
        "        batch_size (:obj:`int`, optional):batch size used for training the model            \n",
        "            If None, the default batch_size are used.\n",
        "            Defaults to 16 .\n",
        "\n",
        "        lr (:obj:`int`, optional):initial learning rate used for training the model            \n",
        "            If None, the default lr are used.\n",
        "            Defaults to 5e-5 .\n",
        "\n",
        "        model_path (:obj:`str`, optional): path of model you want to re-fine tune on new dataset after saving\n",
        "        Defaults to None.\n",
        "        \n",
        "       \n",
        "    \"\"\"\n",
        "  def __init__(self, labels=None,max_seq_length=256,num_epoch=3,batch_size=16,lr=5e-5, model_path=None\n",
        "                 ):\n",
        "        if labels is None:\n",
        "            self.labels = _DEFAULT_LABELS\n",
        "        self._labels_sorted = sorted(labels)\n",
        "        self._is_trained = False\n",
        "        self.model_name='qarib/bert-base-qarib'\n",
        "        self.task='classification'\n",
        "        self.num_epoch=num_epoch\n",
        "        self.batch_size=batch_size\n",
        "        self.max_seq_length=max_seq_length\n",
        "        self.lr=lr\n",
        "        self.model_path=model_path\n",
        "  def create_label2ind_file(self):\n",
        "\n",
        "    self.label_map = { v:index for index, v in enumerate(self._labels_sorted) }\n",
        "\n",
        "  def save_label2ind_file(self,path):\n",
        "    \"\"\"Save  the label 2 indexr on a given data set.\n",
        "      Args:\n",
        "          Path (:obj:`str`): Path where you want to save the feature vector .\n",
        "              \n",
        "          \n",
        "      \"\"\"\n",
        "    with open(path, 'w') as json_file:\n",
        "        json.dump(self.label_map, json_file)\n",
        "\n",
        "  def data_prepare_BERT(self,X_train,y_train):\n",
        "\n",
        "    train_dataset = BERTDataset(X_train.to_list(),y_train.to_list(),self.model_name,self.max_seq_length,self.label_map)\n",
        "    \n",
        "      \n",
        "    return train_dataset\n",
        "  def data_prepare_BERT_test(self,X_test):\n",
        "\n",
        "    test_dataset = BERTDatasetTest(X_test.to_list(),self.model_name,self.max_seq_length,self.label_map)\n",
        "    \n",
        "    return test_dataset\n",
        "\n",
        "  def model_init(self):\n",
        "    if self.model_path not None:\n",
        "      return AutoModelForSequenceClassification.from_pretrained(self.model_path, return_dict=True, num_labels=len(self.label_map))\n",
        "    else:\n",
        "\n",
        "      return AutoModelForSequenceClassification.from_pretrained(self.model_name, return_dict=True, num_labels=len(self.label_map))\n",
        "  \n",
        "  def compute_metrics(self,p):\n",
        "\n",
        "    #p should be of type EvalPrediction\n",
        "\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    assert len(preds) == len(p.label_ids)\n",
        "    #print(classification_report(p.label_ids,preds))\n",
        "    #print(confusion_matrix(p.label_ids,preds))\n",
        "\n",
        "    macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[0,1])\n",
        "    macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "    macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "    macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "    acc = accuracy_score(p.label_ids,preds)\n",
        "    return {\n",
        "        'macro_f1' : macro_f1,\n",
        "        'macro_f1_pos_neg' : macro_f1_pos_neg,  \n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'accuracy': acc\n",
        "    }\n",
        "\n",
        "  \n",
        "  def save_model(self,path):   \n",
        "    \"\"\"Save  the model on a given data set.\n",
        "        Args:\n",
        "            Path (:obj:`str`): Path where you want to save the model.\n",
        "               \n",
        "           \n",
        "        \"\"\"\n",
        "    self.trainer.save_model(path + '/')\n",
        "\n",
        "  def eval(self,X_eval,y_eval, data_set='DEV'):\n",
        "\n",
        "    \"\"\"Evaluate the trained model on a given data set.\n",
        "        Args:\n",
        "            X_eval (:obj:`np array or pandas series`, optional): loaded data for evaluation.\n",
        "\n",
        "            y_eval (:obj:`np array or pandas series`, optional): loaded labels for evaluation.\n",
        "\n",
        "            data_set (:obj:`str`, optional): Name of the provided data set to\n",
        "                use. This is ignored if data_path is not None. Can be either\n",
        "                'VALIDATION' or 'TEST'. Defaults to 'VALIDATION'.\n",
        "\n",
        "            batch_size (:obj:`int`, optional):batch size used for training the model            \n",
        "            If None, the default batch_size are used.\n",
        "            Defaults to 16 .\n",
        "        Returns:\n",
        "            :obj:`dict`: A dictionary mapping an evaluation metric to its\n",
        "            computed value. The metrics used are accuracy, f1_micro, f1_macro,\n",
        "            recall_micro, recall_macro, precision_micro and precision_macro.\n",
        "        \"\"\"\n",
        "    validation_inputs = self.data_prepare_BERT(X_eval,y_eval)\n",
        "    predictions=self.trainer.predict(validation_inputs)\n",
        "    all_pred=np.argmax(predictions[0],axis=1)\n",
        "    all_label= [self.label_map[i] for i in y_eval]    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    macro_f1_pos_neg = f1_score(all_label, all_pred,average='macro',labels=[0,1])\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    recall = recall_score(all_label, all_pred, average='macro')\n",
        "    precision = precision_score(all_label, all_pred, average='macro')\n",
        "    # Get scores\n",
        "    scores = {\n",
        "        'Sentiment': {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1score,\n",
        "            'recall_macro': recall,\n",
        "            'precision_macro':precision\n",
        "        }\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "  def predict(self,sentences):\n",
        "    \"\"\"Predict the sentiment  probability scores for a given list of\n",
        "        sentences.\n",
        "        Args:\n",
        "            sentences (:obj:`list` of :obj:`str`): The list of sentences.\n",
        "            output (:obj:`str`): The output label type. Possible values are\n",
        "                'postive', 'neagtive', 'neutral'.\n",
        "        Returns:\n",
        "            :obj:`list` of :obj:`sentIDPred`: A list of prediction results,\n",
        "            each corresponding to its respective sentence.\n",
        "        \"\"\"\n",
        "    if isinstance(sentences, str):\n",
        "      sentences=pd.Series(sentences)\n",
        "    validation_inputs = self.data_prepare_BERT_test(sentences)\n",
        "    predictions=self.trainer.predict(validation_inputs)\n",
        "    probabilities=predictions[0]\n",
        "    predicted = np.argmax(predictions[0],axis=1)   \n",
        "    result = collections.deque()\n",
        "    convert = lambda x: x     \n",
        "    for i in range(0,len(predicted)):\n",
        "      for j, val in enumerate(self.label_map):\n",
        "      \n",
        "        if j==predicted[i]:\n",
        "          result.append(convert(SentIDPred(val, probabilities[i])))\n",
        "          break\n",
        "\n",
        "        \n",
        "      \n",
        "    return list(result)    \n",
        "       \n",
        "\n",
        "         \n",
        "\n",
        "  def fine_tune(self,X_train,y_train,X_valid=None,y_valid=None):\n",
        "\n",
        "    \"\"\" fine tune MARBERT model.\n",
        "        Args:\n",
        "            X_train (:obj:`np array or pandas series`, optional): loaded training data.\n",
        "               \n",
        "            y_train (:obj:`np array or pandas series`, optional): loaded labels for training.\n",
        "\n",
        "            X_valid (:obj:`np array or pandas series`, optional): loaded validation data.\n",
        "               \n",
        "            y_valid (:obj:`np array or pandas series`, optional): loaded labels for validation.\n",
        "       \n",
        "        \"\"\"\n",
        "\n",
        "    self.create_label2ind_file()\n",
        "    if X_valid is None and y_valid is None:\n",
        "      msk = np.random.rand(len(X_train)) < 0.8\n",
        "      X_valid = X_train[~msk]\n",
        "      X_train = X_train[msk]\n",
        "      y_valid = y_train[~msk]\n",
        "      y_train = y_train[msk]\n",
        "    #-------------------------------------------------------\n",
        "    train_inputs = self.data_prepare_BERT(X_train,y_train)\n",
        "    validation_inputs = self.data_prepare_BERT(X_valid,y_valid)\n",
        "      \n",
        "    #-------------------------------------------------------\n",
        "    training_args = TrainingArguments(\"./train\")\n",
        "    training_args.evaluate_during_training = True\n",
        "    training_args.adam_epsilon = 1e-8\n",
        "    training_args.learning_rate = self.lr\n",
        "    training_args.fp16 = True\n",
        "    training_args.per_device_train_batch_size = self.batch_size\n",
        "    training_args.per_device_eval_batch_size = self.batch_size\n",
        "    training_args.gradient_accumulation_steps = 2\n",
        "    training_args.num_train_epochs= self.num_epoch\n",
        "    steps_per_epoch = (len(X_train)// (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\n",
        "    total_steps = steps_per_epoch * training_args.num_train_epochs\n",
        "    \n",
        "    #Warmup_ratio\n",
        "    warmup_ratio = 0.1\n",
        "    training_args.warmup_steps = total_steps*warmup_ratio # or you can set the warmup steps directly \n",
        "\n",
        "    training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
        "    # training_args.logging_steps = 200\n",
        "    training_args.save_steps = 100000 #don't want to save any model, there is probably a better way to do this :)\n",
        "    training_args.seed = 42\n",
        "    training_args.disable_tqdm = False\n",
        "    training_args.lr_scheduler_type = 'cosine'\n",
        "\n",
        "    #-------------------------------------------------------\n",
        "    self.trainer = Trainer(\n",
        "    model = self.model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_inputs,\n",
        "    eval_dataset=validation_inputs,\n",
        "    compute_metrics=self.compute_metrics,\n",
        ")\n",
        "\n",
        "    #------------------------------------------\n",
        "    self.trainer.train()\n",
        "    \n",
        "    #---------------------------------------------------\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbSE86REiRYt"
      },
      "source": [
        "import collections\n",
        "class SentIDPred(collections.namedtuple('SentimentPred', ['top', 'scores'])):\n",
        "    \"\"\"A named tuple containing sentiment ID prediction results.\n",
        "    Attributes:\n",
        "        top (:obj:`str`): The sentiment label with the highest score. See\n",
        "            :ref:`sentimentid_labels` for a list of output labels.\n",
        "        scores (:obj:`dict`): A dictionary mapping each sentiment label to it's\n",
        "            computed score.\n",
        "    \"\"\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIqttStecsh7"
      },
      "source": [
        "class SentimentIdentificationQaribTPrediction(object):\n",
        "  \"\"\"A class for running a fine-tuned sentiment analysis model to predict\n",
        "    the sentiment of given sentences.\n",
        "\n",
        "\n",
        "    Args:\n",
        "        labels (:obj:`set` of :obj:`str`, optional): The set of dialect labels\n",
        "            used in the training data in the main model.\n",
        "            If None, the default labels are used.\n",
        "            Defaults to None.\n",
        "\n",
        "        training_model_path (:obj:`str`, optional): Path of training model to be used for inference,\n",
        "        If none, use defult model for this libaray\n",
        "\n",
        "        label2index (:obj:`str`, optional): Path of label 2 indexx file to be used for scoring,\n",
        "        If none, use defult model for this libaray\n",
        "\n",
        "        max_seq_length (:obj:`int`, optional): maximum sequence length for the model\n",
        "            \n",
        "            If None, the default max_seq_length are used.\n",
        "            Defaults to 256 .\n",
        "\n",
        "    \"\"\"\n",
        "  def __init__(self, labels=None,training_model_path=None,label2index=None,max_seq_length=256,\n",
        "                batch_size=16 ):\n",
        "        if labels is None:\n",
        "            self.labels = _DEFAULT_LABELS\n",
        "        self._labels_sorted = sorted(labels)\n",
        "        self.model_name='qarib/bert-base-qarib'\n",
        "        self.task='classification'\n",
        "        self.batch_size=batch_size\n",
        "        self.max_seq_length=max_seq_length\n",
        "        if label2index is None:\n",
        "          self.label_map = json.load(open(LABEL_2_INDEX_PATH))\n",
        "        else:\n",
        "          self.label_map =  json.load(open(label2index))\n",
        "\n",
        "        if training_model_path is None:\n",
        "\n",
        "          self.trainer = Trainer(\n",
        "            model = self.model_init(MODEL_PATH_),\n",
        "            # args = training_args,\n",
        "            # train_dataset = train_dataset,\n",
        "            # eval_dataset=test_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "          \n",
        "        else:\n",
        "           self.trainer = Trainer(\n",
        "            model = self.model_init(training_model_path),\n",
        "            # args = training_args,\n",
        "            # train_dataset = train_dataset,\n",
        "            # eval_dataset=test_dataset,\n",
        "            compute_metrics=self.compute_metrics,\n",
        "        )\n",
        "  def model_init(self,Path=None):\n",
        "    if Path is None:\n",
        "      return AutoModelForSequenceClassification.from_pretrained(self.model_name, return_dict=True, num_labels=len(self.label_map)) \n",
        "    else:\n",
        "      return AutoModelForSequenceClassification.from_pretrained(Path, return_dict=True, num_labels=len(self.label_map)) \n",
        "  def compute_metrics(self,p):\n",
        "\n",
        "    #p should be of type EvalPrediction\n",
        "\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    assert len(preds) == len(p.label_ids)\n",
        "    #print(classification_report(p.label_ids,preds))\n",
        "    #print(confusion_matrix(p.label_ids,preds))\n",
        "\n",
        "    macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[0,1])\n",
        "    macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "    macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "    macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "    acc = accuracy_score(p.label_ids,preds)\n",
        "    return {\n",
        "        'macro_f1' : macro_f1,\n",
        "        'macro_f1_pos_neg' : macro_f1_pos_neg,  \n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'accuracy': acc\n",
        "    }\n",
        "\n",
        "        \n",
        "  def data_prepare_BERT(self,X_train,y_train):\n",
        "\n",
        "    train_dataset = BERTDataset(X_train.to_list(),y_train.to_list(),self.model_name,self.max_seq_length,self.label_map)\n",
        "    \n",
        "      \n",
        "    return train_dataset\n",
        "  def data_prepare_BERT_test(self,X_test):\n",
        "\n",
        "    test_dataset = BERTDatasetTest(X_test.to_list(),self.model_name,self.max_seq_length,self.label_map)\n",
        "    \n",
        "    return test_dataset\n",
        "  def eval(self,X_eval,y_eval, data_set='DEV'):\n",
        "\n",
        "    \"\"\"Evaluate the trained model on a given data set.\n",
        "        Args:\n",
        "            X_eval (:obj:`np array or pandas series`, optional): loaded data for evaluation.\n",
        "\n",
        "            y_eval (:obj:`np array or pandas series`, optional): loaded labels for evaluation.\n",
        "\n",
        "            data_set (:obj:`str`, optional): Name of the provided data set to\n",
        "                use. This is ignored if data_path is not None. Can be either\n",
        "                'VALIDATION' or 'TEST'. Defaults to 'VALIDATION'.\n",
        "        Returns:\n",
        "            :obj:`dict`: A dictionary mapping an evaluation metric to its\n",
        "            computed value. The metrics used are accuracy, f1_micro, f1_macro,\n",
        "            recall_micro, recall_macro, precision_micro and precision_macro.\n",
        "        \"\"\"\n",
        "    validation_inputs = self.data_prepare_BERT(X_eval,y_eval)\n",
        "    predictions=self.trainer.predict(validation_inputs)\n",
        "    all_pred=np.argmax(predictions[0],axis=1)\n",
        "    all_label= [self.label_map[i] for i in y_eval]    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    macro_f1_pos_neg = f1_score(all_label, all_pred,average='macro',labels=[0,1])\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    recall = recall_score(all_label, all_pred, average='macro')\n",
        "    precision = precision_score(all_label, all_pred, average='macro')\n",
        "    # Get scores\n",
        "    scores = {\n",
        "        'Sentiment': {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1score,\n",
        "            'recall_macro': recall,\n",
        "            'precision_macro':precision\n",
        "        }\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "  def predict(self,sentences):\n",
        "    \"\"\"Predict the sentiment  probability scores for a given list of\n",
        "        sentences.\n",
        "        Args:\n",
        "            sentences (:obj:`list` of :obj:`str`): The list of sentences.\n",
        "            output (:obj:`str`): The output label type. Possible values are\n",
        "                'postive', 'neagtive', 'neutral'.\n",
        "        Returns:\n",
        "            :obj:`list` of :obj:`SentIDPred`: A list of prediction results,\n",
        "            each corresponding to its respective sentence.\n",
        "        \"\"\"\n",
        "    if isinstance(sentences, str):\n",
        "      sentences=pd.Series(sentences)\n",
        "    validation_inputs = self.data_prepare_BERT_test(sentences)\n",
        "    predictions=self.trainer.predict(validation_inputs)\n",
        "    probabilities=predictions[0]\n",
        "    predicted = np.argmax(predictions[0],axis=1)   \n",
        "    result = collections.deque()\n",
        "    convert = lambda x: x     \n",
        "    for i in range(0,len(predicted)):\n",
        "      for j, val in enumerate(self.label_map):\n",
        "      \n",
        "        if j==predicted[i]:\n",
        "          result.append(convert(SentIDPred(val, probabilities[i])))\n",
        "          break\n",
        "\n",
        "        \n",
        "      \n",
        "    return list(result)\n",
        "        \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rnbIM_hYN1a"
      },
      "source": [
        "# Testing Production code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoqGSsUzYNUI"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Omdena_sentiment/Dataset/final_text.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QxVgIOPYdJr"
      },
      "source": [
        "msk = np.random.rand(len(df)) < 0.7\n",
        "train = df[msk]\n",
        "test = df[~msk]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Donm5w_VYe0p"
      },
      "source": [
        "msk = np.random.rand(len(train)) < 0.8\n",
        "train_new = train[msk]\n",
        "valid = train[~msk]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJFtZwWsYg3d"
      },
      "source": [
        "labels_numeric=[0,1,2]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNEqmzbUYivv",
        "outputId": "e7b5e078-9292-4dfd-fa33-6178ba82ef3d"
      },
      "source": [
        "train_new.dropna(inplace=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wfbdf1VYkVT",
        "outputId": "99ddc02d-0973-45d7-ffb4-962b395e67e0"
      },
      "source": [
        "test.dropna(inplace=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7vZzyIYlha",
        "outputId": "3c8de5ce-4a3e-45a1-e446-b3665018f0b8"
      },
      "source": [
        "valid.dropna(inplace=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdtYDdeLYnFR"
      },
      "source": [
        "Qarib_Sentiment_Classifier=SentimentIdentificationQarib(labels_numeric,num_epoch=3)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "7b7fcee4b2034b3db427fe124ecf901e",
            "44d71c990df044d4a15d6d75d0c5d474",
            "5f2e7c5d5a634f16ade73da1b519da79",
            "4e05fb678b8548bcb00968112a3dba64",
            "aec0616913b24287a01e396430cbc284",
            "94bf31fee4b749ba9f73737c9a571c20",
            "1b801888285e4701a1e82ed7f08d4338",
            "265a315748304e4ebd1b729cc48e80b3"
          ]
        },
        "id": "MOq6WKPhZJVn",
        "outputId": "25bb192d-2f11-48b6-a3f6-58e6a3c0f7bc"
      },
      "source": [
        "Qarib_Sentiment_Classifier.fine_tune(train_new['final'],train_new['label'],valid['final'],valid['label'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b7fcee4b2034b3db427fe124ecf901e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=543452854.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at qarib/bert-base-qarib were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='12093' max='12093' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12093/12093 2:08:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Macro F1 Pos Neg</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.521100</td>\n",
              "      <td>0.566908</td>\n",
              "      <td>0.760829</td>\n",
              "      <td>0.719027</td>\n",
              "      <td>0.781222</td>\n",
              "      <td>0.752370</td>\n",
              "      <td>0.784444</td>\n",
              "      <td>220.924900</td>\n",
              "      <td>144.094000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.519991</td>\n",
              "      <td>0.792210</td>\n",
              "      <td>0.757392</td>\n",
              "      <td>0.796572</td>\n",
              "      <td>0.789237</td>\n",
              "      <td>0.808098</td>\n",
              "      <td>219.514900</td>\n",
              "      <td>145.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.117300</td>\n",
              "      <td>0.809086</td>\n",
              "      <td>0.790234</td>\n",
              "      <td>0.754540</td>\n",
              "      <td>0.793046</td>\n",
              "      <td>0.787827</td>\n",
              "      <td>0.805962</td>\n",
              "      <td>221.139000</td>\n",
              "      <td>143.955000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:911: FutureWarning:\n",
            "\n",
            "Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdJu69QgdmG2"
      },
      "source": [
        "MODEL_PATH_='/content/drive/MyDrive/Omdena_sentiment/Saved_models/Production/QARIB'\n",
        "LABEL_2_INDEX_PATH='/content/drive/MyDrive/Omdena_sentiment/Saved_models/Production/QARIB/_labels_dict.json'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlBNNEMRkySB"
      },
      "source": [
        "Qarib_Sentiment_Classifier.save_model(MODEL_PATH_)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_HD_EB0v6j2"
      },
      "source": [
        "Qarib_Sentiment_Classifier.save_label2ind_file(LABEL_2_INDEX_PATH)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "YLHeA_gWRexV",
        "outputId": "40d1dfae-5bc6-4c17-9289-cf26e3eb0adc"
      },
      "source": [
        "Qarib_Sentiment_Classifier.eval(test['final'],test['label'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='4321' max='4321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4321/4321 08:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': {'accuracy': 0.8082853588682848,\n",
              "  'f1_macro': 0.7925063863858407,\n",
              "  'precision_macro': 0.795478364070367,\n",
              "  'recall_macro': 0.7899674069791708}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "6jf3Qlg4CYcU",
        "outputId": "80dedd17-4b5b-4fc9-cb2d-e90197ce4b7a"
      },
      "source": [
        "Qarib_Sentiment_Classifier.predict('صفاء الهاشم سيده كويتيه المراه الوحيده حاليا مجلس الامه الكويتي مدافعه شرسه حقوق المراه وحق المواطن الكويتي وتمتلك عقليه اقتصاديه مميزه اختيرت ضمن سيده عربيه مؤsثره مجتمعها')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='4323' max='4321' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4321/4321 08:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SentIDPred(top=2, scores=array([-1.259, -2.994,  5.73 ], dtype=float16))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXJGuqCBbj9b"
      },
      "source": [
        "Qarib_predictor=SentimentIdentificationQaribTPrediction(labels=labels_numeric,training_model_path=MODEL_PATH_)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "2co8dizqbNjz",
        "outputId": "b1c68996-395d-493f-f9f0-f33c00e5dc04"
      },
      "source": [
        "Qarib_predictor.predict('صفاء الهاشم سيده كويتيه المراه الوحيده حاليا مجلس الامه الكويتي مدافعه شرسه حقوق المراه وحق المواطن الكويتي وتمتلك عقليه اقتصاديه مميزه اختيرت ضمن سيده عربيه مؤsثره مجتمعها')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SentIDPred(top='2', scores=array([-1.2585853, -2.9939423,  5.7301383], dtype=float32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}