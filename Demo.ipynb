{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u343_onWgl3M"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_YHny8XVwDW",
    "outputId": "9f8cd50e-ceda-410e-f7a4-b676e8f7b838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Omdena-seniment-analysis' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b deep-learning-models https://github.com/MohamadElnomrossie/Omdena-seniment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsU7nx2cgoLi",
    "outputId": "56273a17-f6d8-4de7-95c3-3ddd9cf3eade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Omdena-seniment-analysis\n"
     ]
    }
   ],
   "source": [
    "%cd Omdena-seniment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UoOWtrcxmqDH"
   },
   "outputs": [],
   "source": [
    "# !git clone -b Tokenization https://github.com/OmdenaAI/Arabic-Chapter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lrrXxAugt--"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FKs1usOilOl9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "from Sentiment import SentimentAnalysis\n",
    "from utils import helper, preprocess\n",
    "# from utils.config import config\n",
    "\n",
    "# from ArabicChapter.Tokenizer.tokenizer import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AxlQqXzhLW8"
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "id": "UUphxgKUWdb3",
    "outputId": "c36dd8b6-3ad0-485c-f829-68cac911dc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Text', 'Class_camel', 'cleaned_text', 'mentions',\n",
      "       'word_count', 'contain_emoji', 'demoji_text', 'URLS'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_camel</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>word_count</th>\n",
       "      <th>contain_emoji</th>\n",
       "      <th>demoji_text</th>\n",
       "      <th>URLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>حقوق المرأة 💚💚💚 https://t.co/Mzf90Ta5g1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>حقوق المراه</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>:green_heart::green_heart::green_heart:</td>\n",
       "      <td>['https://t.co/Mzf90Ta5g1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @saud_talep: Retweeted لجنة التنمية بشبرا (...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>لجنه التنميه بشبرا ما زال التسجيل مستمر في دور...</td>\n",
       "      <td>['saud', 'Shubratanmyeh']</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>:sparkles:</td>\n",
       "      <td>['https://t.co/c2NXzNCdLU']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>RT @fatemaar7: انا كامرأة يوجعني كل حزن نساء ا...</td>\n",
       "      <td>negative</td>\n",
       "      <td>انا كامراه يوجعني كل حزن نساء العالم سواء تعنف...</td>\n",
       "      <td>['fatemaar7']</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['https://t.co/c494qBVPx4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>@AliFCD @ShamsanM @AlyemenNor @space_dist @m2r...</td>\n",
       "      <td>negative</td>\n",
       "      <td>غسق وسبيس وحلوه الحلوات هم اشخاص لهم هويتهم وك...</td>\n",
       "      <td>['AliFCD', 'ShamsanM', 'AlyemenNor', 'space', ...</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>RT @Dresraamohammed: السؤال بقى للناس الي شغال...</td>\n",
       "      <td>negative</td>\n",
       "      <td>السؤال بقي للناس الي شغاله في حقوق الانسان حقو...</td>\n",
       "      <td>['Dresraamohammed']</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>:person_facepalming_light_skin_tone::female_si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>إذا كانت مسألة حقوق المرأة أمرا سخيفاً جداً ، ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>اذا كانت مساله حقوق المراه امرا سخيفا جدا فالل...</td>\n",
       "      <td>[]</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>@naifco كل هذه الحقوق او المزعوم انها حقوق عبا...</td>\n",
       "      <td>negative</td>\n",
       "      <td>كل هذه الحقوق او المزعوم انها حقوق عباره عن صف...</td>\n",
       "      <td>['naifco']</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>متى تعرف ان المرأة ما عندها حقوق؟\\r\\n يوم يطبع...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>متي تعرف ان المراه ما عندها حقوق يوم يطبعون له...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>:backhand_index_pointing_down_medium-light_ski...</td>\n",
       "      <td>['https://t.co/7a9H0KQTqH']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>RT @miss_wahaj: @RmNxb المسيار زي زواج المتعه ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>المسيار زي زواج المتعه عند الشيعه نعايب عليهم ...</td>\n",
       "      <td>['miss', 'RmNxb']</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>RT @Gh08944301: @Eqbal_Darandari لمتى واحنا بل...</td>\n",
       "      <td>negative</td>\n",
       "      <td>لمتي واحنا بلا حقوق لانقدر نجدد جوازات سفرنا و...</td>\n",
       "      <td>['Gh08944301', 'Eqbal']</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text Class_camel  \\\n",
       "0           0            حقوق المرأة 💚💚💚 https://t.co/Mzf90Ta5g1     neutral   \n",
       "1           2  RT @saud_talep: Retweeted لجنة التنمية بشبرا (...     neutral   \n",
       "2           5  RT @fatemaar7: انا كامرأة يوجعني كل حزن نساء ا...    negative   \n",
       "3           7  @AliFCD @ShamsanM @AlyemenNor @space_dist @m2r...    negative   \n",
       "4           9  RT @Dresraamohammed: السؤال بقى للناس الي شغال...    negative   \n",
       "5          12  إذا كانت مسألة حقوق المرأة أمرا سخيفاً جداً ، ...    negative   \n",
       "6          13  @naifco كل هذه الحقوق او المزعوم انها حقوق عبا...    negative   \n",
       "7          14  متى تعرف ان المرأة ما عندها حقوق؟\\r\\n يوم يطبع...     neutral   \n",
       "8          16  RT @miss_wahaj: @RmNxb المسيار زي زواج المتعه ...    negative   \n",
       "9          18  RT @Gh08944301: @Eqbal_Darandari لمتى واحنا بل...    negative   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                                        حقوق المراه   \n",
       "1  لجنه التنميه بشبرا ما زال التسجيل مستمر في دور...   \n",
       "2  انا كامراه يوجعني كل حزن نساء العالم سواء تعنف...   \n",
       "3  غسق وسبيس وحلوه الحلوات هم اشخاص لهم هويتهم وك...   \n",
       "4  السؤال بقي للناس الي شغاله في حقوق الانسان حقو...   \n",
       "5  اذا كانت مساله حقوق المراه امرا سخيفا جدا فالل...   \n",
       "6  كل هذه الحقوق او المزعوم انها حقوق عباره عن صف...   \n",
       "7  متي تعرف ان المراه ما عندها حقوق يوم يطبعون له...   \n",
       "8  المسيار زي زواج المتعه عند الشيعه نعايب عليهم ...   \n",
       "9  لمتي واحنا بلا حقوق لانقدر نجدد جوازات سفرنا و...   \n",
       "\n",
       "                                            mentions  word_count  \\\n",
       "0                                                 []           2   \n",
       "1                          ['saud', 'Shubratanmyeh']          15   \n",
       "2                                      ['fatemaar7']          50   \n",
       "3  ['AliFCD', 'ShamsanM', 'AlyemenNor', 'space', ...          32   \n",
       "4                                ['Dresraamohammed']          24   \n",
       "5                                                 []          18   \n",
       "6                                         ['naifco']          16   \n",
       "7                                                 []          13   \n",
       "8                                  ['miss', 'RmNxb']          13   \n",
       "9                            ['Gh08944301', 'Eqbal']          50   \n",
       "\n",
       "   contain_emoji                                        demoji_text  \\\n",
       "0           True            :green_heart::green_heart::green_heart:   \n",
       "1           True                                         :sparkles:   \n",
       "2          False                                                NaN   \n",
       "3          False                                                NaN   \n",
       "4           True  :person_facepalming_light_skin_tone::female_si...   \n",
       "5          False                                                NaN   \n",
       "6          False                                                NaN   \n",
       "7           True  :backhand_index_pointing_down_medium-light_ski...   \n",
       "8          False                                                NaN   \n",
       "9          False                                                NaN   \n",
       "\n",
       "                          URLS  \n",
       "0  ['https://t.co/Mzf90Ta5g1']  \n",
       "1  ['https://t.co/c2NXzNCdLU']  \n",
       "2  ['https://t.co/c494qBVPx4']  \n",
       "3                           []  \n",
       "4                           []  \n",
       "5                           []  \n",
       "6                           []  \n",
       "7  ['https://t.co/7a9H0KQTqH']  \n",
       "8                           []  \n",
       "9                           []  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Datasets/Final_Dataset/Dataset/train.csv\")\n",
    "print(data.columns)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9CTt6ZshzSr",
    "outputId": "6cf60897-aed8-448f-fe00-b03627ad5381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لان تبني حقوق المراه من وجهه نظر علمانيه وتحرريه يضر بمجتمعي ويضر بالنساء والرجال علي حد سواء بس هم ليش مهتمين وحاشرين خشومهم negative\n",
      "حقوق المراه neutral\n",
      "تضامن مع ترف العسيري اختي المسلمه حجابك حشمتك حيائك هي هويتك الحقيقيه التي كرمك بها دينك العظيم حافظي عليها فهي من تمنحك الكرامه والحريه الحقيقيه لاتستمعي لمن يحاول طمس هويتك الاسلاميه تحت دعاوي مزيفه مثل حقوق المراه وبكائيات من تسمين انفسهن ب الناشطات والحقوقيات positive\n"
     ]
    }
   ],
   "source": [
    "print(data.cleaned_text.loc[45], data.Class_camel.loc[45])\n",
    "print(data.cleaned_text.loc[0], data.Class_camel.loc[0])\n",
    "print(data.cleaned_text.loc[35], data.Class_camel.loc[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pk4MSFdeXH43",
    "outputId": "d8e47986-886c-432d-db36-6c35c3e80fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    57096\n",
       "negative    33702\n",
       "neutral     20124\n",
       "Name: Class_camel, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class_camel.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8sr1dkCXlNN"
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EbGnEdu0Xmro"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Datasets/stopWords.pkl\", 'rb') as f:\n",
    "    stop_words = list(pickle.load(f))\n",
    "    stop_words = list(set(stop_words + ['و','في','من','بواسطة','أ','هو','و','في','سيكون','إلى','كان','كن','هو','ال','و','ما','ء','ه','س']))\n",
    "\n",
    "config = {\n",
    "    'vocab_size':60000,\n",
    "    'maxlen':256,\n",
    "    'embedding_vector':50,\n",
    "\n",
    "    'method':'lstm', #other - simpleRNN, bidRNN, 1DConv, lstm\n",
    "    'stop_words':stop_words,\n",
    "    'punctuations':\"\"\"'!\"-#$%&'()*+,«».؛،/:؟?@[\\]^_`{|}~\"\"\",\n",
    "\n",
    "    'epochs':50,\n",
    "    'optim':'SGD', # other - adamax, adadelta, SGD, Adam, RMSprop\n",
    "    'learning_rate':1e-1,\n",
    "\n",
    "    'save_model_path':'models/',\n",
    "    'save_weights_path':\"models/\",\n",
    "    'train_data_path':\"Datasets/Final_Dataset/Dataset/train.csv\",\n",
    "    'val_data_path':\"Datasets/Final_Dataset/Dataset/val.csv\",\n",
    "    'test_data_path':\"Datasets/Final_Dataset/Dataset/test.csv\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQMlDbXohNd-"
   },
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jEvmECaShO-H"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(config['train_data_path'])\n",
    "val_data = pd.read_csv(config['val_data_path'])\n",
    "test_data = pd.read_csv(config['test_data_path'])\n",
    "\n",
    "train_data = train_data.dropna().reset_index(drop=True)\n",
    "val_data = val_data.dropna().reset_index(drop=True)\n",
    "test_data = test_data.dropna().reset_index(drop=True)\n",
    "\n",
    "train_text, train_label = train_data['cleaned_text'].values, train_data['Class_camel'].values\n",
    "val_text, val_label = val_data['cleaned_text'].values, val_data['Class_camel'].values\n",
    "test_text, test_label = test_data['cleaned_text'].values.copy(), test_data['Class_camel'].values.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1vrllETheP0",
    "outputId": "697c2fc8-c8f1-416b-a4cd-db49d0f1b6fb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272fc1869a824a60b4e9adaf4eed1d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29029.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561918a616414ae1aaa1487a26ee4886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7267.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7116f08488bf44318fcb932dfbf30541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15634.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Default Tokenization\n",
    "sentiment = SentimentAnalysis(preprocess.tokenizer, vocab_size=config['vocab_size'], maxlen=config['maxlen'], embedding_vector=config['embedding_vector'], method=config['method'],)\n",
    "\n",
    "train_text = sentiment.tokenize(train_text, punctuations=config['punctuations'], stop_words=config['stop_words'])\n",
    "train_text, train_label, unique_words, word_dict = sentiment.vectorize(train_text, train_label, return_label=True)\n",
    "\n",
    "val_text = sentiment.tokenize(val_text, punctuations=config['punctuations'], stop_words=config['stop_words'])\n",
    "val_text, val_label, _, _ = sentiment.vectorize(val_text, val_label, return_label=True)\n",
    "\n",
    "test_text = sentiment.tokenize(test_text, punctuations=config['punctuations'], stop_words=config['stop_words'])\n",
    "test_text, test_label, _, _ = sentiment.vectorize(test_text, test_label, return_label=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rieReB8pEUR6",
    "outputId": "b8241a71-b746-40f6-c9c6-5285437e78e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['حقوق', 'المراه'], 'neutral')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cleaned_text.iloc[0], train_data.Class_camel.iloc[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEocqAv3EZ0j",
    "outputId": "617ec200-f153-48d3-e21c-acd5fabec39c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([49698,  1937,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]),\n",
       " array([0., 1., 0.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[0], train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZiyIf3NUlX0h",
    "outputId": "4537f8b5-97ff-455e-e543-69bc1142838c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29029, 256) (7267, 256) (29029, 3) (7267, 3)\n",
      "Epoch 1/50\n",
      "908/908 [==============================] - 49s 45ms/step - loss: 0.9982 - accuracy: 0.4924 - precision: 0.4985 - recall: 0.2021 - auc: 0.6787 - val_loss: 0.9777 - val_accuracy: 0.4900 - val_precision: 0.5120 - val_recall: 0.4728 - val_auc: 0.7101\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97767, saving model to models\\lstm_model.h5\n",
      "Epoch 2/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.9566 - accuracy: 0.5003 - precision: 0.5618 - recall: 0.2435 - auc: 0.7124 - val_loss: 0.8954 - val_accuracy: 0.5863 - val_precision: 0.7962 - val_recall: 0.2393 - val_auc: 0.7754\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97767 to 0.89544, saving model to models\\lstm_model.h5\n",
      "Epoch 3/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.8243 - accuracy: 0.6085 - precision: 0.7006 - recall: 0.4291 - auc: 0.8064 - val_loss: 0.7820 - val_accuracy: 0.6287 - val_precision: 0.6748 - val_recall: 0.5572 - val_auc: 0.8285\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89544 to 0.78203, saving model to models\\lstm_model.h5\n",
      "Epoch 4/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.6877 - accuracy: 0.6957 - precision: 0.7418 - recall: 0.6119 - auc: 0.8705 - val_loss: 0.6626 - val_accuracy: 0.7090 - val_precision: 0.7421 - val_recall: 0.6623 - val_auc: 0.8804\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.78203 to 0.66257, saving model to models\\lstm_model.h5\n",
      "Epoch 5/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.5685 - accuracy: 0.7657 - precision: 0.7983 - recall: 0.7157 - auc: 0.9135 - val_loss: 0.6463 - val_accuracy: 0.7246 - val_precision: 0.7545 - val_recall: 0.6889 - val_auc: 0.8886\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66257 to 0.64628, saving model to models\\lstm_model.h5\n",
      "Epoch 6/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.4664 - accuracy: 0.8182 - precision: 0.8428 - recall: 0.7904 - auc: 0.9423 - val_loss: 0.6389 - val_accuracy: 0.7409 - val_precision: 0.7540 - val_recall: 0.7266 - val_auc: 0.8983\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.64628 to 0.63889, saving model to models\\lstm_model.h5\n",
      "Epoch 7/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.3960 - accuracy: 0.8502 - precision: 0.8687 - recall: 0.8301 - auc: 0.9582 - val_loss: 0.6482 - val_accuracy: 0.7478 - val_precision: 0.7604 - val_recall: 0.7325 - val_auc: 0.9076\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.63889\n",
      "Epoch 8/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.3256 - accuracy: 0.8815 - precision: 0.8940 - recall: 0.8675 - auc: 0.9711 - val_loss: 0.6263 - val_accuracy: 0.7584 - val_precision: 0.7872 - val_recall: 0.7249 - val_auc: 0.9007\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.63889 to 0.62629, saving model to models\\lstm_model.h5\n",
      "Epoch 9/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.3407 - accuracy: 0.8796 - precision: 0.8928 - recall: 0.8617 - auc: 0.9687 - val_loss: 0.6425 - val_accuracy: 0.7791 - val_precision: 0.7891 - val_recall: 0.7694 - val_auc: 0.9167\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.62629\n",
      "Epoch 10/50\n",
      "908/908 [==============================] - 40s 44ms/step - loss: 0.2270 - accuracy: 0.9201 - precision: 0.9276 - recall: 0.9133 - auc: 0.9852 - val_loss: 0.6639 - val_accuracy: 0.7765 - val_precision: 0.7879 - val_recall: 0.7663 - val_auc: 0.9163\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.62629\n",
      "Epoch 11/50\n",
      "908/908 [==============================] - 41s 45ms/step - loss: 0.1805 - accuracy: 0.9377 - precision: 0.9447 - recall: 0.9340 - auc: 0.9904 - val_loss: 0.8298 - val_accuracy: 0.7662 - val_precision: 0.7723 - val_recall: 0.7601 - val_auc: 0.8988\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.62629\n",
      "Epoch 12/50\n",
      "908/908 [==============================] - 42s 46ms/step - loss: 0.1605 - accuracy: 0.9469 - precision: 0.9516 - recall: 0.9435 - auc: 0.9919 - val_loss: 1.1770 - val_accuracy: 0.6944 - val_precision: 0.7022 - val_recall: 0.6854 - val_auc: 0.8479\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.62629\n",
      "Epoch 13/50\n",
      "908/908 [==============================] - 41s 45ms/step - loss: 0.1271 - accuracy: 0.9602 - precision: 0.9634 - recall: 0.9566 - auc: 0.9946 - val_loss: 0.8401 - val_accuracy: 0.7857 - val_precision: 0.7882 - val_recall: 0.7824 - val_auc: 0.9107\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.62629\n",
      "Epoch 00013: early stopping\n",
      "489/489 [==============================] - 10s 21ms/step - loss: 0.8465 - accuracy: 0.7812 - precision: 0.7852 - recall: 0.7781 - auc: 0.9096\n",
      "\n",
      "Validation loss: 0.8465467691421509  Validation acc: 0.7812460064888 Precision: 0.7852439880371094 Recall: 0.7781118154525757 Auc Roc: 0.9095731377601624\n"
     ]
    }
   ],
   "source": [
    "model = sentiment.fit(train_text,\n",
    "                    train_label,\n",
    "                    validation_data=(val_text, val_label),\n",
    "                    epochs=config['epochs'],\n",
    "                    method=config['method'])\n",
    "sentiment.evaluate(test_text, test_label, model, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VdcNmHJ8zY_"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swb1YkFH7Wo_",
    "outputId": "7f2594e6-fcd2-449f-b97f-026a17536fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text : سعوديات نطلب اسقاط الولايه سعوديات نطلب اسقاط الولايه هلو بابا سلمان طولتوا مو قال محمد بن سلمان ان الولايه راح تسقط قريب متي هالقريب تري راح عمرنا واحنا ننتظر اسقوطها بليز واعتقونا Label : negative\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab961d0e77746d39e4334b0e8f3e2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Neutral 0.5938876867294312\n",
      "--------------------\n",
      "Text : مبدائيا انا مع حقوق المراه وضد حقوق الرجل Label : neutral\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba84416d5ef4acbb86936047db810ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Positive 0.5096917152404785\n",
      "--------------------\n",
      "Text : تضامن مع ترف العسيري فئه اسقاط الولايه القذره حثاله المجتمع الذين سمعوا عن الحريه فنادوا بخلع الحجاب والملابس ويعتبرونها حريهالشخص الحجاب عباده Label : negative\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b78a016bb5480fb63d300aa953d065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Negative 0.9999344348907471\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nText : {test_data['cleaned_text'].iloc[45]} Label : {test_data['Class_camel'].iloc[45]}\")\n",
    "sentiment.predict_([test_data['cleaned_text'].iloc[45]], model, batch_size=32, print_=True)\n",
    "\n",
    "print(f\"Text : {test_data['cleaned_text'].iloc[0]} Label : {test_data['Class_camel'].iloc[0]}\")\n",
    "sentiment.predict_([test_data['cleaned_text'].iloc[0]], model, batch_size=32, print_=True)\n",
    "\n",
    "print(f\"Text : {test_data['cleaned_text'].iloc[35]} Label : {test_data['Class_camel'].iloc[35]}\")\n",
    "sentiment.predict_([test_data['cleaned_text'].iloc[35]], model, batch_size=32, print_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyIa50hpdmlH"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "id": "zLlnq2aUeC-i",
    "outputId": "2458b597-9d02-451b-8875-4b82d42ca4dd"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c47ddd9bf0ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    642\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m             )\n\u001b[0;32m    646\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data path'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from Sentiment import SentimentAnalysis\n",
    "from utils import helper, preprocess\n",
    "\n",
    "data = pd.read_csv(\"data path\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "g9_bsmIQeC-n"
   },
   "outputs": [],
   "source": [
    "data = data.dropna().reset_index(drop=True)\n",
    "text = data[\"Text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3osee_4ixAd",
    "outputId": "8b8068be-d3bf-4f6d-b88d-7b1444957453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['حقوق المرأة 💚💚💚 https://t.co/Mzf90Ta5g1',\n",
       "       'RT @saud_talep: Retweeted لجنة التنمية بشبرا (@Shubratanmyeh):\\n \\n ما زال التسجيل مستمر في دورة حقوق المرأة بعد الطلاق ✨ #وعيك_يحميك... https://t.co/c2NXzNCdLU',\n",
       "       'RT @Dresraamohammed: السؤال بقى للناس الي شغاله في #حقوق_الانسان #حقوق_المرأة \\n يا ترى في قانون او عقوبه على الزوج الي بيمارس العنف ضد زوجته في الشارع ؟؟؟ 🤦🏻\\u200d♀️👩🏻\\u200d💼',\n",
       "       'متى تعرف ان المرأة ما عندها حقوق؟\\n يوم يطبعون لها ورقة مثل هذي 👇🏼👇🏼👇🏼 https://t.co/7a9H0KQTqH',\n",
       "       '@Almajlliss اتوقع الي حاط الاستفتاء وده يخنق المرأه ويسجنها 😹😹 الحمدالله ديرتنا ديره حقوق للمرأه 🙏😋'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGkDoHrvfpGw",
    "outputId": "1598a229-25bd-459f-9ba9-0afd3aeff359"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29029/29029 [00:04<00:00, 5984.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/lstm_model.h5\")\n",
    "preds = sentiment.predict_(text, model, batch_size=32, print_=False)\n",
    "data[\"prediction\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "J6QNJ1OyiUpt",
    "outputId": "4bd845ef-e1d9-4f70-8d70-09ff1cd273a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_camel</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>word_count</th>\n",
       "      <th>contain_emoji</th>\n",
       "      <th>demoji_text</th>\n",
       "      <th>URLS</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[حقوق, المرأة, 💚💚💚, https, t, co]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>حقوق المراه</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>:green_heart::green_heart::green_heart:</td>\n",
       "      <td>['https://t.co/Mzf90Ta5g1']</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[RT, saud, talep, Retweeted, لجنة, التنمية, بش...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>لجنه التنميه بشبرا ما زال التسجيل مستمر في دور...</td>\n",
       "      <td>['saud', 'Shubratanmyeh']</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>:sparkles:</td>\n",
       "      <td>['https://t.co/c2NXzNCdLU']</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[RT, Dresraamohammed, السؤال, بقى, للناس, الي,...</td>\n",
       "      <td>negative</td>\n",
       "      <td>السؤال بقي للناس الي شغاله في حقوق الانسان حقو...</td>\n",
       "      <td>['Dresraamohammed']</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>:person_facepalming_light_skin_tone::female_si...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>[متى, تعرف, ان, المرأة, عندها, حقوق, يوم, يطبع...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>متي تعرف ان المراه ما عندها حقوق يوم يطبعون له...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>:backhand_index_pointing_down_medium-light_ski...</td>\n",
       "      <td>['https://t.co/7a9H0KQTqH']</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>[Almajlliss, اتوقع, الي, حاط, الاستفتاء, وده, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>اتوقع الي حاط الاستفتاء وده يخنق المراه ويسجنه...</td>\n",
       "      <td>['Almajlliss']</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>:cat_face_with_tears_of_joy::cat_face_with_tea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ... prediction\n",
       "0           0  ...   Negative\n",
       "1           2  ...   Negative\n",
       "2           9  ...   Negative\n",
       "3          14  ...   Negative\n",
       "4          21  ...   Positive\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6AxlQqXzhLW8",
    "eyIa50hpdmlH"
   ],
   "name": "Sentiment Analysis from Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
